{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d40dee24-4918-4ec1-84f2-5739a15fa321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ehr-genai-project-hadi']\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "response = s3.list_buckets()\n",
    "print([bucket['Name'] for bucket in response['Buckets']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "066930f6-b0ed-4bfe-9d88-6aa8503b1b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>65</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>45</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P003</td>\n",
       "      <td>82</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id  age gender\n",
       "0       P001   65      M\n",
       "1       P002   45      F\n",
       "2       P003   82      F"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>diagnosis_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E001</td>\n",
       "      <td>P001</td>\n",
       "      <td>5</td>\n",
       "      <td>I10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E002</td>\n",
       "      <td>P002</td>\n",
       "      <td>2</td>\n",
       "      <td>E11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E003</td>\n",
       "      <td>P003</td>\n",
       "      <td>7</td>\n",
       "      <td>J18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  encounter_id patient_id  length_of_stay diagnosis_code\n",
       "0         E001       P001               5            I10\n",
       "1         E002       P002               2            E11\n",
       "2         E003       P003               7            J18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>claim_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C001</td>\n",
       "      <td>P001</td>\n",
       "      <td>12000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C002</td>\n",
       "      <td>P002</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C003</td>\n",
       "      <td>P003</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  claim_id patient_id  claim_amount\n",
       "0     C001       P001         12000\n",
       "1     C002       P002           800\n",
       "2     C003       P003         20000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P001.json  P002.json  P003.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, json, os\n",
    "\n",
    "os.makedirs('data/fhir_patients', exist_ok=True)\n",
    "\n",
    "# Synthetic patient table\n",
    "patients = pd.DataFrame({\n",
    "    'patient_id': ['P001', 'P002', 'P003'],\n",
    "    'age': [65, 45, 82],\n",
    "    'gender': ['M', 'F', 'F']\n",
    "})\n",
    "patients.to_csv('data/patients.csv', index=False)\n",
    "\n",
    "# Encounters table\n",
    "encounters = pd.DataFrame({\n",
    "    'encounter_id': ['E001', 'E002', 'E003'],\n",
    "    'patient_id': ['P001','P002','P003'],\n",
    "    'length_of_stay': [5, 2, 7],\n",
    "    'diagnosis_code': ['I10','E11','J18']\n",
    "})\n",
    "encounters.to_csv('data/encounters.csv', index=False)\n",
    "\n",
    "# Simulate claims\n",
    "claims = pd.DataFrame({\n",
    "    'claim_id': ['C001','C002','C003'],\n",
    "    'patient_id': ['P001','P002','P003'],\n",
    "    'claim_amount': [12000, 800, 20000]\n",
    "})\n",
    "claims.to_csv('data/claims.csv', index=False)\n",
    "\n",
    "# FHIR JSONs for each patient\n",
    "for idx, row in patients.iterrows():\n",
    "    pt_json = {\n",
    "        \"resourceType\": \"Patient\",\n",
    "        \"id\": row.patient_id,\n",
    "        \"gender\": row.gender.lower(),\n",
    "        \"birthDate\": f\"{2025-row.age}-01-01\"\n",
    "    }\n",
    "    with open(f\"data/fhir_patients/{row.patient_id}.json\", 'w') as f:\n",
    "        json.dump(pt_json, f, indent=2)\n",
    "\n",
    "display(patients, encounters, claims)\n",
    "!ls data/fhir_patients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dece344a-5bf8-4515-8d63-b0ca23805170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded raw_data files to S3!\n"
     ]
    }
   ],
   "source": [
    "import boto3, glob\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket = 'ehr-genai-project-hadi'\n",
    "\n",
    "for filepath in glob.glob('data/*'):\n",
    "    if os.path.isfile(filepath):\n",
    "        key = 'raw_data/' + os.path.basename(filepath)\n",
    "        s3.upload_file(filepath, bucket, key)\n",
    "for filepath in glob.glob('data/fhir_patients/*.json'):\n",
    "    key = 'raw_data/fhir_patients/' + os.path.basename(filepath)\n",
    "    s3.upload_file(filepath, bucket, key)\n",
    "\n",
    "print(\"Uploaded raw_data files to S3!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf9d3fb7-3c53-425b-bf41-c7f6e5112aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['raw_data/claims.csv', 'raw_data/encounters.csv', 'raw_data/fhir_patients/P001.json', 'raw_data/fhir_patients/P002.json', 'raw_data/fhir_patients/P003.json', 'raw_data/patients.csv']\n"
     ]
    }
   ],
   "source": [
    "resp = s3.list_objects_v2(Bucket=bucket, Prefix='raw_data/')\n",
    "print([obj['Key'] for obj in resp.get('Contents', [])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2622f06c-3606-4962-a032-aa2a8daa98c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>diagnosis_code</th>\n",
       "      <th>claim_id</th>\n",
       "      <th>claim_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>65</td>\n",
       "      <td>M</td>\n",
       "      <td>E001</td>\n",
       "      <td>5</td>\n",
       "      <td>I10</td>\n",
       "      <td>C001</td>\n",
       "      <td>12000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>45</td>\n",
       "      <td>F</td>\n",
       "      <td>E002</td>\n",
       "      <td>2</td>\n",
       "      <td>E11</td>\n",
       "      <td>C002</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P003</td>\n",
       "      <td>82</td>\n",
       "      <td>F</td>\n",
       "      <td>E003</td>\n",
       "      <td>7</td>\n",
       "      <td>J18</td>\n",
       "      <td>C003</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id  age gender encounter_id  length_of_stay diagnosis_code claim_id  \\\n",
       "0       P001   65      M         E001               5            I10     C001   \n",
       "1       P002   45      F         E002               2            E11     C002   \n",
       "2       P003   82      F         E003               7            J18     C003   \n",
       "\n",
       "   claim_amount  \n",
       "0         12000  \n",
       "1           800  \n",
       "2         20000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "patients = pd.read_csv(\"data/patients.csv\")\n",
    "encounters = pd.read_csv(\"data/encounters.csv\")\n",
    "claims = pd.read_csv(\"data/claims.csv\")\n",
    "\n",
    "# Merge everything\n",
    "merged = patients.merge(encounters, on=\"patient_id\", how=\"left\") \\\n",
    "                 .merge(claims, on=\"patient_id\", how=\"left\")\n",
    "\n",
    "merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a94aed9c-a977-4116-88f1-7f24cfc823e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>diagnosis_code</th>\n",
       "      <th>claim_id</th>\n",
       "      <th>claim_amount</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>fhir_gender</th>\n",
       "      <th>age_check</th>\n",
       "      <th>gender_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>65</td>\n",
       "      <td>M</td>\n",
       "      <td>E001</td>\n",
       "      <td>5</td>\n",
       "      <td>I10</td>\n",
       "      <td>C001</td>\n",
       "      <td>12000</td>\n",
       "      <td>1960</td>\n",
       "      <td>m</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>45</td>\n",
       "      <td>F</td>\n",
       "      <td>E002</td>\n",
       "      <td>2</td>\n",
       "      <td>E11</td>\n",
       "      <td>C002</td>\n",
       "      <td>800</td>\n",
       "      <td>1980</td>\n",
       "      <td>f</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P003</td>\n",
       "      <td>82</td>\n",
       "      <td>F</td>\n",
       "      <td>E003</td>\n",
       "      <td>7</td>\n",
       "      <td>J18</td>\n",
       "      <td>C003</td>\n",
       "      <td>20000</td>\n",
       "      <td>1943</td>\n",
       "      <td>f</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id  age gender encounter_id  length_of_stay diagnosis_code claim_id  \\\n",
       "0       P001   65      M         E001               5            I10     C001   \n",
       "1       P002   45      F         E002               2            E11     C002   \n",
       "2       P003   82      F         E003               7            J18     C003   \n",
       "\n",
       "   claim_amount  birth_year fhir_gender  age_check  gender_match  \n",
       "0         12000        1960           m         65             1  \n",
       "1           800        1980           f         45             1  \n",
       "2         20000        1943           f         82             1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, os\n",
    "\n",
    "fhir_folder = 'data/fhir_patients'\n",
    "fhir_data = []\n",
    "\n",
    "for fname in os.listdir(fhir_folder):\n",
    "    with open(os.path.join(fhir_folder, fname)) as f:\n",
    "        fhir = json.load(f)\n",
    "        fhir_data.append({\n",
    "            'patient_id': fhir['id'],\n",
    "            'birth_year': int(fhir['birthDate'].split('-')[0]),\n",
    "            'fhir_gender': fhir['gender']\n",
    "        })\n",
    "\n",
    "fhir_df = pd.DataFrame(fhir_data)\n",
    "\n",
    "full_df = merged.merge(fhir_df, on=\"patient_id\", how=\"left\")\n",
    "\n",
    "full_df[\"age_check\"] = 2025 - full_df[\"birth_year\"]\n",
    "full_df[\"gender_match\"] = (full_df[\"gender\"].str.lower() == full_df[\"fhir_gender\"]).astype(int)\n",
    "\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12974397-06a4-4fcd-90d8-395d6ba5a088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved and uploaded to S3.\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = full_df.drop(columns=[\"fhir_gender\", \"birth_year\"])\n",
    "cleaned_df.to_csv(\"data/cleaned_data.csv\", index=False)\n",
    "\n",
    "# Upload to S3\n",
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "s3.upload_file(\"data/cleaned_data.csv\", \"ehr-genai-project-hadi\", \"cleaned_data/cleaned_data.csv\")\n",
    "print(\"Cleaned data saved and uploaded to S3.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c0a03e-fbc2-4feb-a57e-7d58dc518630",
   "metadata": {},
   "source": [
    "## model building\n",
    "\n",
    "high_cost as prediction target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce08e246-a981-4c51-ac69-ebd799fa6b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model data saved and uploaded to S3.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/cleaned_data.csv\")\n",
    "\n",
    "df[\"high_cost\"] = (df[\"claim_amount\"] >= 10000).astype(int)\n",
    "\n",
    "df = df.drop(columns=[\"patient_id\", \"diagnosis_code\"])\n",
    "\n",
    "df.to_csv(\"data/model_input.csv\", index=False)\n",
    "\n",
    "import boto3\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.upload_file(\"data/model_input.csv\", \"ehr-genai-project-hadi\", \"model_data/model_input.csv\")\n",
    "print(\"Model data saved and uploaded to S3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adaa2f80-5652-44fb-80bf-646fedb82b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2025-06-14-16-23-22-450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-14 16:23:22 Starting - Starting the training job...\n",
      "2025-06-14 16:23:45 Starting - Preparing the instances for training...\n",
      "2025-06-14 16:24:08 Downloading - Downloading input data...\n",
      "2025-06-14 16:24:53 Downloading - Downloading the training image......\n",
      "2025-06-14 16:25:49 Training - Training image download completed. Training in progress..\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[34m[2025-06-14 16:25:54.447 ip-10-0-138-230.ec2.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2025-06-14 16:25:54.470 ip-10-0-138-230.ec2.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2025-06-14:16:25:54:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2025-06-14:16:25:54:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2025-06-14:16:25:54:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2025-06-14:16:25:54:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2025-06-14:16:25:54:INFO] Determined 0 GPU(s) available on the instance.\u001b[0m\n",
      "\u001b[34m[2025-06-14:16:25:54:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2025-06-14:16:25:54:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[2025-06-14:16:25:54:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2025-06-14:16:25:54:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2025-06-14:16:25:54:INFO] Train matrix has 3 rows and 8 columns\u001b[0m\n",
      "\u001b[34m[2025-06-14 16:25:54.869 ip-10-0-138-230.ec2.internal:7 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2025-06-14 16:25:54.870 ip-10-0-138-230.ec2.internal:7 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2025-06-14 16:25:54.871 ip-10-0-138-230.ec2.internal:7 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2025-06-14 16:25:54.871 ip-10-0-138-230.ec2.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2025-06-14:16:25:54:INFO] Debug hook created from config\u001b[0m\n",
      "\u001b[34m[16:25:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\u001b[0m\n",
      "\u001b[34m[0]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[2025-06-14 16:25:54.885 ip-10-0-138-230.ec2.internal:7 INFO hook.py:427] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2025-06-14 16:25:54.889 ip-10-0-138-230.ec2.internal:7 INFO hook.py:491] Hook is writing from the hook with pid: 7\u001b[0m\n",
      "\u001b[34m[1]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[2]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[3]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[4]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[5]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[6]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[7]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[8]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[9]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[10]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[11]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[12]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[13]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[14]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[15]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[16]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[17]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[18]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[19]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[20]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[21]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[22]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[23]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[24]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[25]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[26]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[27]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[28]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[29]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[30]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[31]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[32]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[33]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[34]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[35]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[36]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[37]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[38]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[39]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[40]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[41]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[42]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[43]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[44]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[45]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[46]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[47]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[48]#011train-logloss:0.69315\u001b[0m\n",
      "\u001b[34m[49]#011train-logloss:0.69315\u001b[0m\n",
      "\n",
      "2025-06-14 16:26:13 Uploading - Uploading generated training model\n",
      "2025-06-14 16:26:13 Completed - Training job completed\n",
      "Training seconds: 125\n",
      "Billable seconds: 125\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.estimator import Estimator\n",
    "import pandas as pd\n",
    "\n",
    "session = sagemaker.Session()\n",
    "bucket = 'ehr-genai-project-hadi'\n",
    "role = sagemaker.get_execution_role()\n",
    "region = session.boto_region_name\n",
    "\n",
    "prefix = \"model_data\"\n",
    "s3_path = f\"s3://{bucket}/{prefix}/model_input.csv\"\n",
    "\n",
    "df = pd.read_csv(\"data/model_input.csv\")\n",
    "df.to_csv(\"data/model_input.csv\", index=False)\n",
    "session.upload_data(\"data/model_input.csv\", bucket=bucket, key_prefix=prefix)\n",
    "\n",
    "df = pd.read_csv(\"data/model_input.csv\")\n",
    "columns = df.columns.tolist()\n",
    "train_cols = [col for col in columns if col != \"high_cost\"]\n",
    "df_xgb = df[[\"high_cost\"] + train_cols]\n",
    "df_xgb.to_csv(\"data/train_xgb.csv\", header=False, index=False)\n",
    "\n",
    "xgb_uri = session.upload_data(\"data/train_xgb.csv\", bucket=bucket, key_prefix=\"xgboost/input\")\n",
    "\n",
    "from sagemaker.image_uris import retrieve\n",
    "image_uri = retrieve(\"xgboost\", region, \"1.5-1\")\n",
    "\n",
    "xgb_estimator = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    volume_size=5,\n",
    "    max_run=300,\n",
    "    input_mode=\"File\",\n",
    "    output_path=f\"s3://{bucket}/xgboost/output\",\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "\n",
    "xgb_estimator.set_hyperparameters(objective=\"binary:logistic\", num_round=50)\n",
    "\n",
    "xgb_estimator.fit({\"train\": TrainingInput(xgb_uri, content_type=\"csv\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5c3861-2759-4566-a37f-8e89d660b62e",
   "metadata": {},
   "source": [
    "## Add GenAI Explanation for Predictions using LLMs\n",
    "\n",
    "Use a Large Language Model (LLM) to explain each prediction (e.g., why a patient was flagged high-risk) in plain English using structured features from your dataset.\n",
    "\n",
    "### Prompt Example\n",
    "Given this patient:\n",
    "\n",
    "- Age: 82\n",
    "- Length of stay: 7\n",
    "- Claim amount: $20,000\n",
    "\n",
    "Explain in 2–3 sentences why this patient is at high risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7df4519-8c38-4385-bd4e-9175bc98dfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.86.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (4.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Downloading openai-1.86.0-py3-none-any.whl (730 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m730.3/730.3 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Installing collected packages: jiter, httpcore, distro, httpx, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [openai]2m4/5\u001b[0m [openai]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed distro-1.9.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.10.0 openai-1.86.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2318f2a-8c7d-4678-9067-82fc7bfc1c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b12b518d-5beb-49c8-bcc3-e0492a9581b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved with explanations.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/model_input.csv\")\n",
    "\n",
    "high_risk = df[df[\"claim_amount\"] >= 10000].copy()\n",
    "\n",
    "high_risk = high_risk.head(2).copy()\n",
    "\n",
    "high_risk[\"GenAI_Explanation\"] = [\n",
    "    \"This 65-year-old patient had a moderately long hospital stay of 5 days and incurred a claim amount of $12,000, suggesting a complex or resource-intensive hospitalization. At this age, patients often have underlying chronic conditions that increase the likelihood of complications or slower recovery. These factors place the patient at elevated risk for both readmission and high post-discharge care needs.\",\n",
    "    \"At 82 years old, this patient falls into a high-risk age group with increased vulnerability to adverse outcomes. A 7-day hospital stay combined with a $20,000 claim suggests significant medical intervention, possibly related to multiple comorbidities or an acute exacerbation of a chronic disease. The advanced age and high cost together indicate a strong risk for readmission and future complications.\"\n",
    "]\n",
    "\n",
    "high_risk.to_csv(\"data/high_risk_explained.csv\", index=False)\n",
    "print(\"Saved with explanations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77ed1fc4-e1ff-4b63-ac90-057d4de11da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  lost+found  Untitled.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22df689a-a439-4394-b4f5-e9b18c938bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
